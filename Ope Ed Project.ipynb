{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Michael McCormack***\n",
    "\n",
    "In the Week 04 file folder you'll find the anonymous New York op ed from September 5, 2018, together with samples of writings of the main suspects. \n",
    "\n",
    "Use any tools you like to figure out who wrote the op ed. If you can find more writings of these people, please send them my way.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How I approached this problem - \n",
    "\n",
    "Let me first say that this is a incredibly interesting problem that demonstrates a very relevant application of NLP.  I had a lot of fun doing this project. \n",
    "\n",
    "I began by doing some exploring on the internet.  I came across this idea of determining author based on sentence structure.  Below is an example of this idea used in a Kaggle competition.\n",
    "\n",
    "https://www.kaggle.com/christopher22/stylometry-identify-authors-by-sentence-structure/notebook\n",
    "\n",
    "Basically the idea is that you break down each training document by sentence and add a label for the author of each sentence.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I start off by reading in the training files into pandas DataFrames.  I then add a column indicating the author Next I concatenate all the dataframes together so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Dan Coats.txt', 'r+') as in_file:\n",
    "    textDan = in_file.read()\n",
    "    sentsDan = nltk.sent_tokenize(textDan)\n",
    "    \n",
    "pdDan = pd.DataFrame({'sentence':sentsDan})\n",
    "pdDan['author'] = 'Dan Coats'\n",
    "\n",
    "\n",
    "with open('James Mattis.txt', 'r+') as in_file:\n",
    "    textMattis = in_file.read()\n",
    "    sentsMattis = nltk.sent_tokenize(textMattis)\n",
    "    \n",
    "pdMattis = pd.DataFrame({'sentence':sentsMattis})\n",
    "pdMattis['author'] = 'James Mattis'\n",
    "\n",
    "\n",
    "with open('John Kelly.txt', 'r+') as in_file:\n",
    "    textKelly = in_file.read()\n",
    "    sentsKelly = nltk.sent_tokenize(textKelly)\n",
    "    \n",
    "pdKelly = pd.DataFrame({'sentence':sentsKelly})\n",
    "pdKelly['author'] = 'John Kelly'\n",
    "\n",
    "\n",
    "with open('Kevin Hassett.txt', 'r+') as in_file:\n",
    "    textHassett = in_file.read()\n",
    "    sentsHassett = nltk.sent_tokenize(textHassett)\n",
    "    \n",
    "pdHassett = pd.DataFrame({'sentence':sentsHassett})\n",
    "pdHassett['author'] = 'Kevin Hassett'\n",
    "\n",
    "with open('Kirstjen Nielsen.txt', 'r+') as in_file:\n",
    "    textNielsen = in_file.read()\n",
    "    sentsNielsen = nltk.sent_tokenize(textNielsen)\n",
    "    \n",
    "pdNielsen = pd.DataFrame({'sentence':sentsNielsen})\n",
    "pdNielsen['author'] = 'Kirstjen Nielsen'\n",
    "\n",
    "with open('Larry Kudlow.txt', 'r+') as in_file:\n",
    "    textKudlow = in_file.read()\n",
    "    sentsKudlow = nltk.sent_tokenize(textKudlow)\n",
    "    \n",
    "pdKudlow = pd.DataFrame({'sentence':sentsKudlow})\n",
    "pdKudlow['author'] = 'Larry Kudlow'\n",
    "\n",
    "\n",
    "with open('Mike Pence.txt', 'r+') as in_file:\n",
    "    textPence = in_file.read()\n",
    "    sentsPence = nltk.sent_tokenize(textPence)\n",
    "    \n",
    "pdPence = pd.DataFrame({'sentence':sentsPence})\n",
    "pdPence['author'] = 'Mike Pence'\n",
    "\n",
    "with open('Mike Pompeo.txt', 'r+') as in_file:\n",
    "    textPompeo = in_file.read()\n",
    "    sentsPompeo = nltk.sent_tokenize(textPompeo)\n",
    "    \n",
    "pdPompeo = pd.DataFrame({'sentence':sentsPompeo})\n",
    "pdPompeo['author'] = 'Mike Pompeo'\n",
    "\n",
    "\n",
    "\n",
    "train = pd.DataFrame()\n",
    "train = pd.concat([pdDan, pdMattis,pdKelly,pdHassett,pdNielsen,pdKudlow,pdPence,pdPompeo])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_to_num ={'Dan Coats': \"Chicken\", 'James Mattis': \"Punk\", \n",
    "                'John Kelly': \"perp\", 'Kevin Hassett': \"Garbage\",\n",
    "                  'Kirstjen Nielsen': \"Scum\", 'Larry Kudlow': \"Toilet\", \n",
    "                'Mike Pence': \"Poop\", 'Mike Pompeo': \"Yuck\"}\n",
    "\n",
    "train[\"author\"].replace(author_to_num, inplace=True)\n",
    "author = train['author'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are  1069 sentences\n"
     ]
    }
   ],
   "source": [
    "text = train['sentence'].tolist()\n",
    "\"\"\"\n",
    "get rid of non-breaking spaces,\n",
    "double spaces,\n",
    "NEW LINES\n",
    "other unicode\n",
    "\"\"\"\n",
    "text = [t.replace('\\xa0', ' ').replace(\"\\u2028\", \" \").replace(u'\\ufeff',' ') \\\n",
    "        .replace('\\n', \" \").replace(\"  \", \" \") for t in text]\n",
    "\n",
    "print(\"there are \", len(text), \"sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(text)#train['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(text, author, test_size=0.25, random_state=1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=0,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents='unicode', sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "ngram range is the bounds for ngrams to be extracted\n",
    "here, we do word unigram and bigrams\n",
    "\n",
    "min_df is setting thresh for minimal number of occurences.\n",
    "\"\"\"\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), min_df=0,\n",
    "                            strip_accents=\"unicode\")\n",
    "\n",
    "vectorizer.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the tf-idf vectors have  17963 dimensions\n",
      "testing accuracy:  squared_hinge\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Chicken       0.91      0.58      0.71        36\n",
      "    Garbage       0.69      0.77      0.73        56\n",
      "       Poop       1.00      0.75      0.86        16\n",
      "       Punk       0.86      0.67      0.75        27\n",
      "       Scum       1.00      1.00      1.00         8\n",
      "     Toilet       0.72      0.70      0.71        44\n",
      "       Yuck       0.80      0.76      0.78        37\n",
      "       perp       0.64      0.93      0.76        44\n",
      "\n",
      "avg / total       0.78      0.75      0.75       268\n",
      "\n",
      "\n",
      "Model test results for Linear SVC:\n",
      "\n",
      "Precision: 0.753731343283582\n",
      "Recall: 0.753731343283582\n",
      "Accuracy: 0.753731343283582\n",
      "Support: None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_vect = vectorizer.transform(X_train)\n",
    "print(\"the tf-idf vectors have \", X_train_vect.shape[-1], \"dimensions\")\n",
    "\n",
    "### Test the model\n",
    "#X_train, X_test, y_train, y_test = train_test_split(vectors, author, test_size=0.35, random_state=1337)\n",
    "svm = LinearSVC()\n",
    "svm.fit(X_train_vect, y_train)\n",
    "\n",
    "print(\"testing accuracy: \", svm.loss)\n",
    "\n",
    "X_test_vect = vectorizer.transform(X_test)\n",
    "predictions = svm.predict(X_test_vect)\n",
    "#print(list(predictions[0:10]))\n",
    "\n",
    "\n",
    "precision, recall, fscore, support = score(y_test, predictions, average=\"micro\")\n",
    "accuracy = round((accuracy_score(y_test, predictions) *100))\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "print(\"\"\"\n",
    "Model test results for Linear SVC:\n",
    "\n",
    "Precision: {}\n",
    "Recall: {}\n",
    "Accuracy: {}\n",
    "Support: {}\n",
    "\"\"\".format(precision, recall, fscore, support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opEd = pd.read_table(\"OpEd.txt\", header =None)\n",
    "#opEd.columns = ['text']\n",
    "\n",
    "#test = opEd['text'].tolist()\n",
    "\n",
    "\n",
    "with open('OpEd.txt', 'r+') as in_file:\n",
    "    textOpEd = in_file.read()\n",
    "    sentsOpEd = nltk.sent_tokenize(textOpEd)\n",
    "\n",
    "\n",
    "test = pd.DataFrame({'sentence':sentsOpEd})\n",
    "print(test)\n",
    "\n",
    "X_test=vectorizer.transform(test)\n",
    "\n",
    "# testVector = vectorizer.fit_transform(test)\n",
    "# X_test=vectorizer.transform(test)\n",
    "# print(vectors.shape)\n",
    "\n",
    "\n",
    "predictions = svm.predict(X_test)\n",
    "\n",
    "#predictedAuthor = mode(predictions)\n",
    "\n",
    "predictedAuthordf = pd.DataFrame(predictions)\n",
    "predictedAuthordf.columns = ['Author']\n",
    "predictedAuthordf = predictedAuthordf['Author'].value_counts().reset_index()\n",
    "predictedAuthordf = pd.DataFrame(predictedAuthordf)\n",
    "predictedAuthordf.columns = ['Author','Count']\n",
    "predictedAuthordf[\"Probability\"] = predictedAuthordf[\"Count\"]/(predictedAuthordf['Count'].sum())\n",
    "predictedAuthordf[\"logLikelihood\"] = np.log( predictedAuthordf[\"Probability\"])\n",
    "\n",
    "prediction = predictedAuthordf['logLikelihood'].idxmax()\n",
    "predictedAuthor = predictedAuthordf.at[prediction,'Author']\n",
    "\n",
    "print(predictedAuthordf,\"\\n\\n\")\n",
    "\n",
    "\n",
    "#predictedAuthor = (list(possibleAuthors.keys())[list(possibleAuthors.values()).index(predictedAuthor)]) \n",
    "print(\"The predicted author is: \", predictedAuthor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing prediction distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "bins = len(set(predictions))\n",
    "\n",
    "plt.hist(predictions, color = \"skyblue\", normed=True, align=\"mid\",bins= bins)\n",
    "plt.xticks(range(bins))\n",
    "plt.ylabel(\"Probability\",fontsize=16)\n",
    "plt.xlabel(\"Author\",fontsize=16)\n",
    "plt.title(\"Distribution of Predictions\",fontsize=20)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "c = collections.Counter(predictions)\n",
    "c = sorted(c.items())\n",
    "months_num = [i[0] for i in c]\n",
    "freq = [i[1] for i in c]\n",
    "\n",
    "suffixes = []\n",
    "for item in months_num:\n",
    "    suffixes.append(item.split()[-1])\n",
    "    \n",
    "    \n",
    "\n",
    "plt.bar(suffixes, freq)\n",
    "plt.xlabel(\"Author\",fontsize=16)\n",
    "plt.ylabel(\"Count\",fontsize=16)\n",
    "plt.title(\"Counts of Predicted Authors\", fontsize=20)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
